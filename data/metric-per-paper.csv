idx,title,venue,status,num_metrics,metrics
0,Is Quantization a Deal-breaker? Empirical Insights from Large Code Models,arXiv,ok,9,Composite/Quality-cost trade-off; Computational/Parameters; Computational/Peak memory; Computational/Speedup ratio; Environmental/Carbon emissions; Environmental/Energy consumption; Task Quality/Accuracy; Task Quality/Precision / Recall; Task Quality/pass@k
1,Greening Large Language Models of Code,arXiv,ok,9,Composite/Quality-cost trade-off; Computational/FLOPs; Computational/Latency; Computational/Parameters; Computational/Speedup ratio; Environmental/Carbon emissions; Environmental/Energy consumption; Environmental/Monetary cost; Task Quality/Accuracy
2,"On the Compression of Language Models for Code: Distillation, Quantization, and Pruning",arXiv,ok,13,Composite/Quality-cost trade-off; Computational/FLOPs; Computational/Latency; Computational/Parameters; Computational/Peak memory; Computational/Speedup ratio; Environmental/Carbon emissions; Environmental/Energy consumption; Task Quality/Accuracy; Task Quality/BLEU / CodeBLEU; Task Quality/F1 score; Task Quality/MRR / Recall@k; Task Quality/Precision / Recall
3,A Metamorphic Testing Perspective on Knowledge Distillation for Code,arXiv,ok,13,Composite/Quality-cost trade-off; Computational/FLOPs; Computational/Latency; Computational/Parameters; Computational/Peak memory; Computational/Speedup ratio; Environmental/Carbon emissions; Environmental/Energy consumption; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/BLEU / CodeBLEU; Task Quality/F1 score; Task Quality/Precision / Recall
4,Compressing Pre-trained Models of Code into 3 MB,ASE,ok,8,Computational/FLOPs; Computational/Latency; Computational/Parameters; Computational/Peak memory; Computational/Speedup ratio; Computational/Training time; Environmental/Monetary cost; Task Quality/Accuracy
5,An Empirical Study of Knowledge Distillation for Code Understanding Tasks,ICSE,ok,9,Composite/Quality-cost trade-off; Computational/Latency; Computational/Parameters; Computational/Speedup ratio; Computational/Training time; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/F1 score; Task Quality/MRR / Recall@k
6,Compact Language Models via Pruning and Knowledge Distillation (Minitron),NeurIPS,ok,7,Composite/Quality-cost trade-off; Composite/Tokens / Turns (agent cost); Computational/FLOPs; Computational/Parameters; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/pass@k
7,FineSec: Distilling Lightweight Language Models for C/C++ Vulnerabilities,arXiv,ok,6,Composite/Quality-cost trade-off; Computational/Latency; Computational/Parameters; Computational/Peak memory; Task Quality/Accuracy; Task Quality/Precision / Recall
8,LoRACode: LoRA Adapters for Code Embeddings,ICLR,ok,6,Computational/Latency; Computational/Parameters; Computational/Peak memory; Computational/Training time; Task Quality/Accuracy; Task Quality/MRR / Recall@k
9,PEFT for Large Models: A Comprehensive Survey,arXiv,ok,12,Composite/Compression ratio; Composite/Quality-cost trade-off; Computational/Latency; Computational/Parameters; Computational/Peak memory; Computational/Speedup ratio; Computational/Throughput; Computational/Training time; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/MRR / Recall@k; Task Quality/Precision / Recall
10,Astraios: Parameter-Efficient Instruction Tuning Code LLMs,ICLR,ok,7,Composite/Quality-cost trade-off; Computational/Parameters; Computational/Training time; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/F1 score; Task Quality/pass@k
11,PEFT of Small LMs for Code Generation (Gemma/Qwen/Llama),IJECE,no_pdf,0,
12,Draft & Verify: Lossless LLM Acceleration via Self-Speculative Decoding,ACL,ok,11,Composite/Compression ratio; Composite/Quality-cost trade-off; Computational/Latency; Computational/Parameters; Computational/Peak memory; Computational/Speedup ratio; Computational/Throughput; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/BLEU / CodeBLEU; Task Quality/pass@k
13,LayerSkip: Enabling Early-Exit Inference and Self-Speculative Decoding,arXiv,ok,11,Composite/Quality-cost trade-off; Computational/Latency; Computational/Parameters; Computational/Peak memory; Computational/Speedup ratio; Computational/Throughput; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/BLEU / CodeBLEU; Task Quality/MRR / Recall@k; Task Quality/pass@k
14,DynamicKV: Task-Aware Adaptive KV Cache Compression,Findings of EMNLP,ok,8,Computational/Latency; Computational/Peak memory; Computational/Throughput; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/BLEU / CodeBLEU; Task Quality/F1 score; Task Quality/Precision / Recall
15,LaCache: Ladder-Shaped KV Caching for Efficient Long-Context Modeling,ICML,no_pdf,0,
16,Efficient LLM Inference on CPUs,arXiv,ok,7,Composite/Quality-cost trade-off; Computational/Latency; Computational/Parameters; Computational/Peak memory; Computational/Speedup ratio; Task Quality/Accuracy; Task Quality/Precision / Recall
17,Attaining Cheaper and Faster Completion through Dynamic Model Inference,arXiv,ok,9,Composite/Quality-cost trade-off; Computational/Parameters; Computational/Speedup ratio; Environmental/Carbon emissions; Environmental/Energy consumption; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/BLEU / CodeBLEU; Task Quality/Precision / Recall
18,Accelerating Inference of RAG via Sparse Context Selection,NeurIPS,ok,9,Composite/Quality-cost trade-off; Computational/Latency; Computational/Parameters; Computational/Peak memory; Computational/Speedup ratio; Computational/Throughput; Task Quality/Accuracy; Task Quality/F1 score; Task Quality/Precision / Recall
19,Accelerating LLM Inference for Efficient Code Generation,arXiv,ok,7,Composite/Quality-cost trade-off; Composite/Tokens / Turns (agent cost); Computational/Latency; Computational/Parameters; Computational/Peak memory; Computational/Speedup ratio; Task Quality/pass@k
20,Speculative Decoding for Verilog,arXiv,ok,6,Computational/Latency; Computational/Peak memory; Computational/Speedup ratio; Computational/Throughput; Task Quality/Accuracy; Task Quality/pass@k
21,FrugalGPT: How to Use LLMs While Reducing Cost,arXiv,ok,6,Computational/Latency; Computational/Speedup ratio; Computational/Throughput; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/Precision / Recall
22,RouteLLM: Learning to Route LLMs with Preference Data,ICLR,ok,4,Composite/Quality-cost trade-off; Computational/Latency; Computational/Parameters; Environmental/Monetary cost
23,Hybrid LLM: Cost-Efficient and Quality-Aware Query Routing,ICLR,ok,12,Composite/Quality-cost trade-off; Composite/Tokens / Turns (agent cost); Computational/FLOPs; Computational/Latency; Computational/Parameters; Computational/Speedup ratio; Environmental/Energy consumption; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/BLEU / CodeBLEU; Task Quality/MRR / Recall@k; Task Quality/Precision / Recall
24,AutoMix: Automatically Mixing Language Models,NeurIPS,ok,9,Composite/Quality-cost trade-off; Computational/Latency; Computational/Parameters; Computational/Training time; Environmental/Energy consumption; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/F1 score; Task Quality/Precision / Recall
25,FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness,NeurIPS,ok,10,Composite/Compression ratio; Computational/FLOPs; Computational/Latency; Computational/Parameters; Computational/Peak memory; Computational/Speedup ratio; Computational/Throughput; Computational/Training time; Task Quality/Accuracy; Task Quality/Precision / Recall
26,Switch Transformers: Scaling to Trillion Parameter Models,JMLR,ok,12,Composite/Quality-cost trade-off; Composite/Tokens / Turns (agent cost); Computational/FLOPs; Computational/Latency; Computational/Parameters; Computational/Peak memory; Computational/Speedup ratio; Computational/Training time; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/BLEU / CodeBLEU; Task Quality/Precision / Recall
27,DeepSeekMoE: Towards Ultimate Expert Specialization,arXiv,ok,4,Computational/FLOPs; Computational/Parameters; Task Quality/Accuracy; Task Quality/pass@k
28,EffiCoder: Enhancing Code Generation through Efficiency-Aware Fine-tuning,ICML,ok,6,Computational/Latency; Computational/Peak memory; Computational/Training time; Environmental/Energy consumption; Task Quality/MRR / Recall@k; Task Quality/pass@k
29,GREEN-CODE: Learning to Optimize Energy Efficiency in LLM-based Code Generation,arXiv,ok,12,Composite/Quality-cost trade-off; Computational/Latency; Computational/Parameters; Computational/Peak memory; Computational/Throughput; Environmental/Carbon emissions; Environmental/Energy consumption; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/BLEU / CodeBLEU; Task Quality/MRR / Recall@k; Task Quality/Precision / Recall
30,Arctic-SnowCoder: Demystifying High-Quality Data in Code Pretraining,arXiv,ok,5,Computational/Parameters; Environmental/Monetary cost; Task Quality/AUROC / AUC; Task Quality/Precision / Recall; Task Quality/pass@k
31,"Code Less, Align More: Efficient LLM Fine-tuning with Data Pruning",arXiv,ok,6,Composite/Compression ratio; Computational/FLOPs; Computational/Parameters; Computational/Training time; Task Quality/Accuracy; Task Quality/pass@k
32,Learn to Code Sustainably: An Empirical Study on LLM-based Green Code Generation,arXiv,ok,9,Computational/FLOPs; Computational/Latency; Computational/Parameters; Computational/Peak memory; Computational/Training time; Environmental/Carbon emissions; Environmental/Energy consumption; Task Quality/Accuracy; Task Quality/MRR / Recall@k
33,Carbon Footprint Evaluation of Code Generation through LLM as a Service,arXiv,ok,6,Computational/FLOPs; Computational/Latency; Computational/Peak memory; Environmental/Carbon emissions; Environmental/Energy consumption; Task Quality/Accuracy
34,Analyzing the Energy and Accuracy of LLMs in Software Development,arXiv,ok,14,Composite/Quality-cost trade-off; Composite/Tokens / Turns (agent cost); Computational/Latency; Computational/Parameters; Computational/Peak memory; Environmental/Carbon emissions; Environmental/Energy consumption; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/BLEU / CodeBLEU; Task Quality/Code coverage; Task Quality/Precision / Recall; Task Quality/Resolve rate / Fix rate; Task Quality/pass@k
35,Does Few-Shot Learning Help LLM Performance in Code Synthesis?,arXiv,ok,3,Composite/Quality-cost trade-off; Environmental/Monetary cost; Task Quality/pass@k
36,On Inter-Dataset Code Duplication and Data Leakage in LLMs,IEEE TSE,ok,2,Task Quality/BLEU / CodeBLEU; Task Quality/MRR / Recall@k
37,Scaling Laws for Code: Every Programming Language Matters,arXiv,ok,8,Composite/Quality-cost trade-off; Composite/Tokens / Turns (agent cost); Computational/FLOPs; Computational/Parameters; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/BLEU / CodeBLEU; Task Quality/pass@k
38,Scaling Laws Behind Code Understanding Model,arXiv,ok,6,Computational/FLOPs; Computational/Parameters; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/MRR / Recall@k; Task Quality/Precision / Recall
39,Fast and Memory-Efficient Neural Code Completion,MSR,ok,7,Composite/Quality-cost trade-off; Computational/Parameters; Computational/Peak memory; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/MRR / Recall@k; Task Quality/Precision / Recall
40,A Transformer-Based Approach for Smart Invocation of Automatic Code Completion,arXiv,ok,6,Computational/Latency; Computational/Parameters; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/BLEU / CodeBLEU; Task Quality/MRR / Recall@k
41,How GitHub Copilot Manages Latency,arXiv,ok,9,Composite/Quality-cost trade-off; Computational/Parameters; Computational/Speedup ratio; Environmental/Carbon emissions; Environmental/Energy consumption; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/BLEU / CodeBLEU; Task Quality/Precision / Recall
42,CodeSage: Code Representation Learning At Scale,ICLR,ok,3,Computational/Parameters; Task Quality/F1 score; Task Quality/MRR / Recall@k
43,CodeTransformer: Modeling ASTs with Self-Attention,ICML Workshop,ok,4,Composite/Quality-cost trade-off; Computational/Speedup ratio; Task Quality/MRR / Recall@k; Task Quality/Precision / Recall
44,Seismic: Efficient Inverted Indexes for Approximate Retrieval,SIGIR,ok,8,Composite/Quality-cost trade-off; Computational/Latency; Computational/Speedup ratio; Computational/Throughput; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/MRR / Recall@k; Task Quality/Precision / Recall
45,DeepCodeSeek: Real-Time API Retrieval,arXiv,ok,6,Computational/Latency; Computational/Parameters; Computational/Tail latency (P50/P95/P99); Task Quality/Accuracy; Task Quality/MRR / Recall@k; Task Quality/Precision / Recall
46,Leveraging LLMs for Software Requirements Traceability,arXiv,ok,1,Task Quality/Precision / Recall
47,FLAMES: Memory-Efficient LLMs for Program Repair,ICSE,ok,8,Composite/Quality-cost trade-off; Computational/Parameters; Computational/Peak memory; Environmental/Monetary cost; Task Quality/Code coverage; Task Quality/MRR / Recall@k; Task Quality/Precision / Recall; Task Quality/Resolve rate / Fix rate
48,CigaR: Cost-efficient Program Repair with LLMs,arXiv,ok,7,Composite/Quality-cost trade-off; Composite/Tokens / Turns (agent cost); Computational/Parameters; Environmental/Energy consumption; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/Resolve rate / Fix rate
49,RepairLLaMA: Efficient Representations and Fine-Tuned Adapters,arXiv,ok,8,Composite/Quality-cost trade-off; Computational/Latency; Computational/Parameters; Computational/Peak memory; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/Precision / Recall; Task Quality/Resolve rate / Fix rate
50,Accelerating APR with Dual Retrieval-Augmented Fine-Tuning,arXiv,ok,7,Composite/Quality-cost trade-off; Computational/Latency; Computational/Parameters; Computational/Speedup ratio; Task Quality/Accuracy; Task Quality/BLEU / CodeBLEU; Task Quality/Precision / Recall
51,WilliamT: Cheap Crash-Site Program Repair,arXiv,ok,7,Composite/Quality-cost trade-off; Composite/Tokens / Turns (agent cost); Computational/FLOPs; Computational/Latency; Environmental/Monetary cost; Task Quality/Precision / Recall; Task Quality/Resolve rate / Fix rate
52,Automated Program Repair via Conversation (ChatGPT),ESEM,no_pdf,0,
53,ThinkRepair: Self-Directed Automated Program Repair,ISSTA,ok,3,Computational/Training time; Environmental/Monetary cost; Task Quality/Precision / Recall
54,Code Repair with LLMs gives an Exploration-Exploitation Tradeoff,NeurIPS,ok,7,Composite/Quality-cost trade-off; Composite/Tokens / Turns (agent cost); Computational/Speedup ratio; Environmental/Monetary cost; Task Quality/AUROC / AUC; Task Quality/Code coverage; Task Quality/MRR / Recall@k
55,White-Basilisk: A Hybrid Model for Code Vulnerability Detection,arXiv,ok,8,Composite/Quality-cost trade-off; Computational/Parameters; Computational/Peak memory; Environmental/Carbon emissions; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/F1 score; Task Quality/Precision / Recall
56,DeepDFA: Dataflow Analysis-Inspired Deep Learning,ICSE,ok,12,Composite/Tokens / Turns (agent cost); Computational/FLOPs; Computational/Latency; Computational/Parameters; Computational/Peak memory; Computational/Speedup ratio; Computational/Training time; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/F1 score; Task Quality/MRR / Recall@k; Task Quality/Precision / Recall
57,MAGNET: Meta-Path Based Attentional Graph Learning,IEEE TSE,ok,3,Task Quality/Accuracy; Task Quality/F1 score; Task Quality/Precision / Recall
58,MultiGLICE: Combining GNN and Program Slicing,Computers (MDPI),no_pdf,0,
59,Detecting Code Vulnerabilities with Heterogeneous GNN Training,arXiv,ok,4,Task Quality/Accuracy; Task Quality/F1 score; Task Quality/MRR / Recall@k; Task Quality/Precision / Recall
60,GNN-Powered Vulnerability Path Discovery in Open Source Code,arXiv,ok,4,Composite/Tokens / Turns (agent cost); Task Quality/Code coverage; Task Quality/F1 score; Task Quality/Precision / Recall
61,Enhancing Software Vulnerability Detection Using CPGs and CNNs,arXiv,ok,5,Computational/Latency; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/F1 score; Task Quality/Precision / Recall
62,Bridging Semantics and Structure for Vulnerability Detection using Hybrid Network Models,arXiv,ok,6,Composite/Quality-cost trade-off; Composite/Tokens / Turns (agent cost); Computational/Parameters; Task Quality/Accuracy; Task Quality/MRR / Recall@k; Task Quality/Precision / Recall
63,LLM Agent for Real-World OSS Vulnerability Localization,arXiv,ok,6,Computational/Latency; Computational/Throughput; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/MRR / Recall@k; Task Quality/Precision / Recall
64,Enhancing Pre-Trained LMs for Vulnerability Detection via Data Augmentation,arXiv,ok,4,Task Quality/Accuracy; Task Quality/F1 score; Task Quality/MRR / Recall@k; Task Quality/Precision / Recall
65,MAGNET: A Multi-Graph Attentional Network for Code Clone Detection,arXiv,ok,5,Composite/Quality-cost trade-off; Computational/Training time; Task Quality/Accuracy; Task Quality/F1 score; Task Quality/Precision / Recall
66,"Nearest-neighbor, BERT-based, scalable clone detection",SPE,no_pdf,0,
67,An Empirical Study of LLM-Based Code Clone Detection,arXiv,ok,5,Composite/Quality-cost trade-off; Computational/Parameters; Task Quality/Accuracy; Task Quality/F1 score; Task Quality/Precision / Recall
68,SWE-agent: Agent-Computer Interfaces Enable Automated SE,NeurIPS,ok,9,Composite/Quality-cost trade-off; Composite/Tokens / Turns (agent cost); Computational/Speedup ratio; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/F1 score; Task Quality/MRR / Recall@k; Task Quality/Resolve rate / Fix rate; Task Quality/pass@k
69,OpenHands: An Open Platform for AI Software Developers,ICLR,ok,8,Composite/Tokens / Turns (agent cost); Computational/FLOPs; Computational/Latency; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/F1 score; Task Quality/Resolve rate / Fix rate; Task Quality/pass@k
70,SWE-Pruner: Self-Adaptive Context Pruning for Coding Agents,arXiv,ok,9,Composite/Compression ratio; Composite/Quality-cost trade-off; Composite/Tokens / Turns (agent cost); Computational/Latency; Computational/Parameters; Computational/Speedup ratio; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/Resolve rate / Fix rate
71,AutoCodeRover: Autonomous Program Improvement,ISSTA,no_pdf,0,
72,CodeAgent: Autonomous Communicative Agents for Code Review,EMNLP,ok,4,Computational/Latency; Task Quality/Accuracy; Task Quality/F1 score; Task Quality/Precision / Recall
73,RepoNavigator: RL of LLM Agents for Repository-Level Navigation,arXiv,ok,5,Composite/Tokens / Turns (agent cost); Computational/Parameters; Task Quality/F1 score; Task Quality/MRR / Recall@k; Task Quality/Precision / Recall
74,Experience-Driven Early Termination for Cost-Efficient SE Agents,arXiv,ok,4,Composite/Tokens / Turns (agent cost); Environmental/Carbon emissions; Environmental/Monetary cost; Task Quality/MRR / Recall@k
75,Energy Efficiency in Agentic Issue Resolution with SLMs,arXiv,ok,10,Composite/Quality-cost trade-off; Composite/Tokens / Turns (agent cost); Computational/Latency; Computational/Parameters; Computational/Peak memory; Computational/Tail latency (P50/P95/P99); Environmental/Carbon emissions; Environmental/Energy consumption; Environmental/Monetary cost; Task Quality/Accuracy
76,SWE-Replay: Efficient Test-Time Scaling for SE Agents,arXiv,ok,5,Composite/Quality-cost trade-off; Computational/Latency; Computational/Speedup ratio; Environmental/Monetary cost; Task Quality/Resolve rate / Fix rate
77,Adaptive Confidence Gating in Multi-Agent Code Generation,arXiv,ok,7,Composite/Quality-cost trade-off; Composite/Tokens / Turns (agent cost); Computational/FLOPs; Computational/Latency; Computational/Parameters; Task Quality/Accuracy; Task Quality/pass@k
78,Scaling Test-Time Compute for Software Engineering,arXiv,ok,1,Environmental/Monetary cost
79,Enhancing SE Agents via Scaling Test-Time Compute,arXiv,ok,3,Task Quality/Accuracy; Task Quality/F1 score; Task Quality/MRR / Recall@k
80,Self-Refine: Iterative Refinement with Self-Feedback,NeurIPS,ok,6,Composite/Tokens / Turns (agent cost); Computational/Speedup ratio; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/MRR / Recall@k; Task Quality/Precision / Recall
81,Reflexion: Language Agents with Verbal Reinforcement Learning,NeurIPS,ok,6,Composite/Tokens / Turns (agent cost); Computational/Latency; Computational/Parameters; Task Quality/Accuracy; Task Quality/Precision / Recall; Task Quality/pass@k
82,Teaching Large Language Models to Self-Debug,ICLR,ok,5,Computational/Parameters; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/MRR / Recall@k; Task Quality/pass@k
83,SWE-Effi: Re-Evaluating Under Resource Constraints,arXiv,ok,8,Composite/Quality-cost trade-off; Composite/Tokens / Turns (agent cost); Computational/Latency; Computational/Parameters; Environmental/Monetary cost; Task Quality/AUROC / AUC; Task Quality/Accuracy; Task Quality/Resolve rate / Fix rate
84,FuseSearch: Learning Adaptive Parallel Execution for Efficient Code Localization,arXiv,ok,10,Composite/Quality-cost trade-off; Composite/Tokens / Turns (agent cost); Computational/Latency; Computational/Parameters; Computational/Speedup ratio; Computational/Throughput; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/F1 score; Task Quality/Precision / Recall
85,CodaMosa: Escaping Coverage Plateaus with Pre-trained LLMs,ICSE,no_pdf,0,
86,ASTER: Natural and Multi-language Unit Test Generation,ICSE SEIP,ok,5,Composite/Tokens / Turns (agent cost); Computational/Parameters; Environmental/Carbon emissions; Environmental/Monetary cost; Task Quality/Code coverage
87,TestGenEval: Real World Unit Test Generation Benchmark,ICLR,ok,6,Computational/Parameters; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/BLEU / CodeBLEU; Task Quality/Code coverage; Task Quality/pass@k
88,Harnessing LLMs for Automated Software Testing: Scalable Test Case Generation,arXiv,ok,1,Task Quality/F1 score
89,How well LLM-based test generation techniques perform with newer LLM versions?,arXiv,ok,4,Composite/Quality-cost trade-off; Composite/Tokens / Turns (agent cost); Computational/Latency; Task Quality/Code coverage
90,CodeT: Code Generation with Generated Tests,ICLR,ok,3,Task Quality/Accuracy; Task Quality/Code coverage; Task Quality/pass@k
91,EffiBench: Benchmarking the Efficiency of Automatically Generated Code,NeurIPS,ok,7,Computational/Latency; Computational/Peak memory; Environmental/Carbon emissions; Environmental/Energy consumption; Task Quality/Accuracy; Task Quality/MRR / Recall@k; Task Quality/pass@k
92,Learning Performance-Improving Code Edits (PIE),ICLR,ok,6,Composite/Quality-cost trade-off; Computational/Latency; Computational/Speedup ratio; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/Precision / Recall
93,SWE-Effi: Re-Evaluating Under Resource Constraints,arXiv,ok,8,Composite/Quality-cost trade-off; Composite/Tokens / Turns (agent cost); Computational/Latency; Computational/Parameters; Environmental/Monetary cost; Task Quality/AUROC / AUC; Task Quality/Accuracy; Task Quality/Resolve rate / Fix rate
94,CodeBERT: A Pre-Trained Model for Programming and Natural Languages,Findings of EMNLP,ok,3,Task Quality/Accuracy; Task Quality/BLEU / CodeBLEU; Task Quality/MRR / Recall@k
95,GraphCodeBERT: Pre-training Code Representations with Data Flow,ICLR,ok,6,Computational/Speedup ratio; Task Quality/Accuracy; Task Quality/BLEU / CodeBLEU; Task Quality/F1 score; Task Quality/MRR / Recall@k; Task Quality/Precision / Recall
96,UniXcoder: Unified Cross-Modal Pre-training for Code Representation,ACL,ok,6,Computational/Parameters; Task Quality/Accuracy; Task Quality/BLEU / CodeBLEU; Task Quality/F1 score; Task Quality/MRR / Recall@k; Task Quality/Precision / Recall
97,Code Llama: Open Foundation Models for Code,arXiv,ok,11,Computational/FLOPs; Computational/Latency; Computational/Parameters; Computational/Training time; Environmental/Carbon emissions; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/BLEU / CodeBLEU; Task Quality/MRR / Recall@k; Task Quality/Precision / Recall; Task Quality/pass@k
98,StarCoder: may the source be with you!,TMLR,ok,13,Computational/Parameters; Computational/Peak memory; Computational/Throughput; Computational/Training time; Environmental/Carbon emissions; Environmental/Energy consumption; Environmental/Monetary cost; Task Quality/Accuracy; Task Quality/BLEU / CodeBLEU; Task Quality/F1 score; Task Quality/MRR / Recall@k; Task Quality/Precision / Recall; Task Quality/pass@k
99,DeepSeek-Coder: When the LLM Meets Programming,arXiv,ok,6,Composite/Quality-cost trade-off; Computational/Latency; Computational/Parameters; Computational/Throughput; Task Quality/Accuracy; Task Quality/pass@k
100,code2vec: Learning Distributed Representations of Code,POPL,no_pdf,0,
101,Structural Language Models of Code,ICML,ok,3,Computational/Parameters; Task Quality/Accuracy; Task Quality/MRR / Recall@k
102,AST-T5: Structure-Aware Pretraining for Code Generation and Understanding,ICML,ok,7,Computational/Parameters; Computational/Speedup ratio; Task Quality/Accuracy; Task Quality/BLEU / CodeBLEU; Task Quality/F1 score; Task Quality/MRR / Recall@k; Task Quality/pass@k
